<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=description content="7/8 3 day maintenance window from July 15 to 22nd
Sagar Rawal
Next week
h100 wide issue
start w the issue"><title>h100 remediation worklog
</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://azhou35.github.io/my-digital-garden//icon.png><link href=https://azhou35.github.io/my-digital-garden/styles.591589daec716a7d5287f8d56c2c091e.min.css rel=stylesheet><link href=https://azhou35.github.io/my-digital-garden/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://azhou35.github.io/my-digital-garden/js/darkmode.111b0c7178f4cf301c69a167d6c795e4.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script src=https://unpkg.com/@floating-ui/core@0.7.3></script><script src=https://unpkg.com/@floating-ui/dom@0.5.4></script><script src=https://azhou35.github.io/my-digital-garden/js/popover.37b1455b8f0603154072b9467132c659.min.js></script><script src=https://azhou35.github.io/my-digital-garden/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script><script src=https://azhou35.github.io/my-digital-garden/js/clipboard.25155053855f45fdc48fd92540bcebc9.min.js></script><script>const BASE_URL="https://azhou35.github.io/my-digital-garden/",fetchData=Promise.all([fetch("https://azhou35.github.io/my-digital-garden/indices/linkIndex.160e3dae0ccc3e93f972ff9a8ab8e8f2.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://azhou35.github.io/my-digital-garden/indices/contentIndex.20674002f1e4267a795bceb51bea9460.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL(BASE_URL),s=n.pathname,o=window.location.pathname,i=s==o;addCopyButtons(),addTitleToCodeBlocks();const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!1;drawGraph("https://azhou35.github.io/my-digital-garden",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://azhou35.github.io/my-digital-garden",!0,!0)},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/azhou35.github.io\/my-digital-garden\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J")}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script><script defer src=https://azhou35.github.io/my-digital-garden/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://azhou35.github.io/my-digital-garden/>ðŸª´ anniez</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg>
</label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>h100 remediation worklog</h1><p class=meta>Last updated
Unknown</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#78>7/8</a></li><li><a href=#77>7/7</a></li><li><a href=#7725>7/7/25</a></li></ol></nav></details></aside><a href=#78><h2 id=78><span class=hanchor arialabel=Anchor># </span>7/8</h2></a><ul><li><p>3 day maintenance window from July 15 to 22nd</p></li><li><p>Sagar Rawal</p></li><li><p>Next week</p></li><li><p>h100 wide issue</p></li><li><p>start w the issue</p></li><li><p>going into whats happening with oai</p></li><li><p>whats our plan</p></li><li><p>what are we doing</p></li><li><p>we&rsquo;ve talked about how money we&rsquo;ve lost</p></li><li><p>start out with the issue</p><ul><li>work w rameez with the issue</li><li>jer-ming may be</li><li>how big is oai deployment what</li></ul></li><li><p>he cares about business impact and this will save this money</p></li><li><p>how fast can this be done</p></li><li><p>he doesn&rsquo;t rlly understand maintenance</p></li><li><p>have a slide ready for what our plan is</p></li><li><p>here&rsquo;s how we normally do maintenance</p></li><li><p>now we&rsquo;re doing this a few nodes at a time</p></li><li><p>how is it helping</p></li><li><p>what is it helping us achieve overall</p></li><li><p>focus on the what and the why</p></li><li><p>how can be</p></li><li><p>if you need someone else to co-present</p></li><li><p>keep the flow chart in the appendix</p></li><li><p>next Wednesday</p><ul><li>let you know when ill have slides ready</li></ul></li><li><p>when saagar is back</p><ul><li>send a message to do a sync</li><li>do boris sync</li><li>with rameez</li></ul></li><li><p>Align on an overall plan for OAI</p></li><li><p>Think about what Sagar cares about - how long will u take cluster away from me</p><ul><li>3-4 days</li></ul></li><li><p>planning to set up a 1-time call</p></li><li><p>worked with Boris and Oswaldo and update owners who can comment further</p></li><li><p>typically our software procedure is to take the entire cluster down and roll it out at a cluster level - so the way we define a maintenance duration is from when the entire cluster is deallocated, and when the entire cluster is returned</p></li><li><p>with the hardware updates this fundamentally changes the timing and complexity of operations</p><ul><li>as nodes go thru hardware replacement they&rsquo;ll automatically pick up software updates</li></ul></li><li><p>what we can still do at a fabric level with the switch + ufm update</p><ul><li>and also change the custom environment to configure for the new os and hca</li><li>this has historically taken 8 hours on phx61</li></ul></li><li><p>at a node level</p><ul><li>as nodes get to production</li><li>they pick up and os and hca upon repave</li><li>there&rsquo;s two potential mechanisms of updating CRD - if the FW is not a qualified FW the node can be automatically updated with the CoolVille tool - estimated for 2 hour<ul><li>if the FW is a qualified FW, it still needs the latest fleet CRD, node goes to production so PF agent updates CRD</li></ul></li><li>In either case node picks up OS and HCA - which estimated for 1 hr</li></ul></li><li><p>in terms of timing</p></li><li><p>we&rsquo;re gonna need to manage oai&rsquo;s expectations</p><ul><li>what oai cares about is after they deallocate their cluster, when will they get their entire cluster back? ie if we take 500 nodes away when will they get 500 nodes back</li><li>care less about node by node return</li><li>unlike our normal software schedule it&rsquo;s difficult to estimate how long it&rsquo;ll take to roll out updates</li><li>can only get a true estimate after the first time we run it</li><li><ul><li>generally it seems like a 3 day downtime, where the long pole are the hardware updates</li></ul></li><li>or if we better define</li></ul></li><li><p>biggest dependency is to confirm</p></li></ul><p>fix on failure and cluster remediation
based on priority</p><ul><li>what we can assume is after the last gpu baseboard is replaced, itll take the time of node diagnostics + crd update + hca update</li><li>this is not what we want to share with the customer today<ul><li>first we need to align on the hardware part
define something can not have a crd fw mismatch, aka qualified version, but not the latest 1,6,1 crd version
everything is done at a node level
if node comes out</li></ul></li></ul><p>raj:</p><ul><li>need another day to explore</li><li>propose doing 1 cluster within first week<ul><li>first cluster will be bit slow</li><li>3 days and 5 days per day</li></ul></li></ul><p>new versions:</p><ul><li><p>UFM - 1.12.2-2â€‹</p></li><li><p>Switch - 3.12.4002</p></li><li><p>HCA: 28.44.1210</p></li><li><p>CRD: 1.6.1</p></li><li><p>two big questions that affect timing</p><ul><li>how long do diagnostics take?</li></ul></li></ul><a href=#77><h2 id=77><span class=hanchor arialabel=Anchor># </span>7/7</h2></a><p>long pole is hardware
some processes like crd udpates, firmware updates, are automated at a node level.
firmware and all will happen
while ib switch, config changes happen at a cluster level
they vacate
the entire cluster will go to ofr
after nodes go to ofr
they have hardware done
that long pole
as nodes get pushed back node</p><p>disclose that we have to do this work
its going to take capacity of all ur clusters
have to replace hardware
here is a proposal</p><p>whether they want do 1/3 or a cluster</p><p>go to meeting w customer
we need to do this work
we need to change
we need to put in new firmware update</p><blockquote><p><img src="/my-digital-garden/Pasted image 20250707201526.png" width=auto></p></blockquote><ul><li>many things are tested</li><li>after technician does baseboard</li><li>itll take 12 hours</li></ul><p>question -</p><ul><li>we dont know how long node diagnostics flow will take</li><li>coolmile updates will take 2 hours</li><li>Ask Sunita on how long node diagnostics</li><li>we dont normally do pf agents</li><li></li></ul><p>we are working thoroughly</p><p>certificate diagnostics phase take around 12+ hours</p><p>if they cant support to ghr
would we ask oai to deallocate the whole cluster because it cant handle marking nodes as ghr
anticipate
see how long it takes for them to repair the cluster</p><p>get 200 nodes the first day
return as Healthy Empty Nodes</p><p>The other nodes are in OFR
after 1 day theyll get 200 nodes
ask aditya</p><p>move the node to UA
once the
show up to OAI&rsquo;s side at HEN
there has to be a way for us to communicate which</p><p>Questions to clarify with boris</p><ul><li>how long does diagnostics take</li><li>who&rsquo;s doing OFR - using GHR will not work as it has to be an OaaS script they own an dpush for each cluster</li><li>decision to do it on a node level<ul><li>traditionally we&rsquo;ve done it cluster by cluster<ul><li>does OAI prefer a node by node update? Â Depending on what they want to do wit hteh capacity they would have to take a node out of their job, and then bring one in everyday?</li></ul></li><li>ask sunita - up to 12 hours<ul><li>certification - 4 hours</li></ul></li><li>when crd update actually happens<ul><li>within the stage</li><li>dcmx has diff stages</li><li>move from ofr</li><li>proper fault code</li><li>from ofr comes back to certification</li></ul></li></ul></li><li>ask them to disable the auto-scaler cluster by cluster</li><li>make sure tha tall the nodes</li><li>give them green light</li><li>if we make sure whatever capacity is getting crd update is picking up in line new pupdates</li><li>if we have quantitatively validate</li><li>in the first cluster ensure thats the case</li><li>can ask anastasia - nodes that are not allocatable</li><li>timing perspective</li><li>what is p = 0</li><li>what is the time that customer deallocates</li><li>switching the configuration</li><li>making sure the configuration is in place</li><li>everything will be bounded by node repair</li><li>hopefully all the data will be self driven</li><li>do one cluster</li><li></li></ul><a href=#7725><h2 id=7725><span class=hanchor arialabel=Anchor># </span>7/7/25</h2></a><p>for PHX 11 - 1/3 of gpus are
IB Switch - hold down entire cluster at beginning and releasing it as updaes are completed
Node-by-node level:</p><ul><li>Hosting environment is set so nodes get cx7 upon coming out of OFR</li><li>CRD updates would happen after nodes are out of OFR</li><li>Â for CRD two flows: one where nodes are updated in OFR if there is a firmware mismatch, and another where nodes are updated in production if there is no mismatch. The sequence of updates in production needs to be clarified.</li><li>Ask Sunita how long the diagnostics part will take for nodes will go out</li></ul><p>oai -</p><ul><li>does OAI prefer a node by node update? Â Depending on what they want to do wit hteh capacity they would have to take a node out of their job, and then bring one in everyday?</li><li>however, how long would that take the team to swap out node by node to complete an entire cluster?</li></ul><p>if we go from ua
if nodes move to ofr</p><p>nodes will move to ofr for baseboard replacement
theyll get hardware
theyll get os and hca update
that entire process
take a day</p><ul><li>the team can handle 200 nodes per day</li><li>will trickle</li><li>will take 1 cluster 2 1/2 days</li></ul><p>concerns:</p><ul><li><p>will hca going node by node lead to hca misalignment</p></li><li><p>cannot return specific nodes to them</p></li><li><p>what oai sees in ghr is available hand</p></li><li><p>when we move to OFR</p></li><li><p>it goes thru</p></li><li><p>happening on an OFR basis</p></li><li><p>definitely need to take 8 hours of impact</p></li><li><p>as long as these component updates</p></li><li><p>as long as it puts into ofr process</p></li><li><p>we dont know how long itll take to update</p></li><li><p>it&rsquo;s going to happen a little by little</p></li><li><p>mark nodes as ua</p></li><li><p>theyre gonna go thru ofr</p></li><li><p>we&rsquo;re gonna return back to</p></li><li><p>we&rsquo;re gonna take</p></li><li><p>from raj</p></li><li><p>our action: provide a process and some sort of plan to oai tmrw</p><ul><li>on July 15 for 3 days<ul><li>Day 1 - 200 baseboards replaced<ul><li>For every node coming back,</li></ul></li><li>Day 2 - 200 baseboards replaced</li><li>Day 3 - 200 baseboards replaced</li></ul></li><li>For IB - 8 hours per cluster</li></ul></li><li><p><a href="https://microsoft.sharepoint.com/:fl:/g/contentstorage/CSP_6e2552f4-bc0e-4ca3-a434-b084b4981928/EVJVbVaqu89ImrkFvx783Z8B9Fi8-lMoGNH2jPTFQvBylA?e=bVsecQ&amp;nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF82ZTI1NTJmNC1iYzBlLTRjYTMtYTQzNC1iMDg0YjQ5ODE5MjgmZD1iJTIxOUZJbGJnNjhvMHlrTkxDRXRKZ1pLRXJ2end6UjNyVkloUzlXZ01yUkZDRWNucDVyRk44WVFxOFZjMDZHWnJTQSZmPTAxUFZIU0JMMlNLVldWTktWM1o1RUpWT0lGWDRQUFpYTTcmYz0lMkYmYT1Mb29wQXBwJng9JTdCJTIydyUyMiUzQSUyMlQwUlRVSHh0YVdOeWIzTnZablF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUU1Umtsc1ltYzJPRzh3ZVd0T1RFTkZkRXBuV2t0RmNuWjZkM3BTTTNKV1NXaFRPVmRuVFhKU1JrTkZZMjV3TlhKR1RqaFpVWEU0Vm1Nd05rZGFjbE5CZkRBeFVGWklVMEpNTmxWVFdrb3pRa3BCU2pKQ1Jrb3pWMU5OUjFORVEwbElOVTglM0QlMjIlMkMlMjJpJTIyJTNBJTIyMmZhZmRjOTktNmY5Yi00MzkwLTkxNzQtZGE4NTY3YWUyNzEyJTIyJTdE" rel=noopener>H100 Heat Sink Remediation.loop</a>
1 w raghu
1 w schie
1 w oai</p></li></ul><p>lots of issues w
customers have to agree to 3 days of downtime</p><p>Remi</p><p>alternatively all the beginning</p><p>dependency w CRD
CRD would happen w</p><p>CRD doesnt have a similar option of updating upon OFR</p><p>node level hosting to
node pick up os and new hca</p><p>send all nodes to OFR
to get piece of hardware uploaded
crd firmware update standpoint
bucket 1</p><ul><li>node is in ofr and not coming back in production</li><li>node would be parked in ofr</li><li>we would be updated via automation that we call it cool built
bucket 2</li><li>if hardware is replaced, go thru diagnostic flows, and thru diagnostic flow all the firmware vitual</li><li>it will not get mismtch it gets hold</li><li>pf agents will push</li><li>nodes pick up new OS</li><li>if node doesnt get parked in ofr</li><li>we will update it when node gets put into production</li></ul><p>do pushing the updates to production
updates must happen before they return to prodution</p><p>pf team</p><p>if os goes first and then firmware goes its ok
if firmware goes first is there any correlation</p><p>still concerned w sat13</p><p>cx7 fw is not updated by the schie fw deployment team
updated
nodes not coming out of ofr
cx7 update via os
pcie framework in pcie and gpu
mismatch between cx7 f
toady we&rsquo;re not changing the pcie firmware in gpu
spare parts
concern if baseboard has off the shelf retimer framework</p><p>branch this into two parts
if a node is in ofr and theres a firmware mismatch crd will alwyas happen first
if node has no mismatch - this will happen in production
- what will go first? crd update and host os
- if they both run on nodes coming out of ofr is that fine
- ofr</p><p>for ofr -</p><p>outlining these steps</p><ul><li>still trying to figure out what cna be done at a node by node basis</li><li>and what can be done at cluster</li></ul><p>most important t hing to figure out is what they look like
node gets pushed to
diagnostics</p><ol><li>if diagnostics flow - if theres a firmware mismatch
including take action</li></ol><p>depends on what the parts coming with</p><ol><li>what are the</li><li>replace the part</li><li>during diagnostics no firmware mismatch</li><li>ofr - return to production</li><li>agents to do crd update</li><li>question is what we run it</li></ol><p>they repair the node and</p><p>cool ville path</p><ul><li>as nodes come out</li><li>ensure that coolville runs</li><li>ensure that nodes</li><li>want to really guarantee</li></ul><p>as they repair nodes
nodes will go into diagnostiic flow
ofr
IB switches
if ur using ofr to
once diagnostic is complete -
it would take 2 hours per node</p><p>vacate
600 nodes go to ofr
in 6 hours, they would see 20 hours
in next 24 hours
200 nodes will come back</p><p>next 24 hours
next 200 nodes</p><p>200 nodes per day
open nodes
replace the parts</p><p>Diagnostiics - how long ok that will take
Once diagnostics have completed
If it runs every hour
we cant tell them how long the nodes</p><p>maintenance window
3 day</p><p>nodes pick up new OS and new HCA - when ucomplete OS repave you will reboot the node</p><p>reinforcing the messaging that timeline
making sure the schie teams are aligned with my plans</p><ul><li></li></ul><p>question</p><ul><li><p>crd goes first</p></li><li><p>does os update go first</p></li><li><p>when does cool build happen</p></li><li><p>when the node is in ofr</p></li><li><p>host os update would happen in repave</p></li></ul><p>Remi and Annie discussed the challenges of performing a CRD on over 100 clusters, highlighting the reluctance of Byte Dance to provide extended maintenance windows and the potential issues with inference clusters.</p><p>.</p><p><strong>Challenges with CRD:</strong>Â Remi expressed concerns about performing a CRD on over 100 clusters, noting that Byte Dance is only willing to provide a 6-hour maintenance window, and any downtime beyond that would be their responsibility. This creates significant pressure to complete the updates within the limited timeframe.</p><p>.</p><p><strong>Inference Clusters:</strong>Â Annie mentioned that she lacks visibility into the inference clusters and is more focused on training remediation. She suggested sharing the schedule for GPU-based boards to guide the discussion on what is feasible for their teams.</p><p>.</p><p><strong>Inglewood Clusters:</strong>Â Remi noted that they are more up-to-date on the Inglewood clusters, which makes it easier to get maintenance windows, although the stakeholders are not enthusiastic about the maintenance either.</p><p><strong>Training Remediation Context:</strong>Â Annie explained their focus on training remediation for specific clusters and shared the schedule for GPU baseboard updates, which are planned to be done in phases from July to September.</p><p>.</p><p><strong>Training Remediation Focus:</strong>Â Annie clarified that her focus is on training remediation for specific clusters, specifically 11/27/61, and she does not have much visibility into Byte Dance or inference clusters.</p><p>.</p><p><strong>GPU Baseboard Updates:</strong>Â Annie shared the schedule for updating GPU baseboards, which involves doing a third of a cluster at a time across different clusters from July to September. The updates are expected to start around July 21st.</p><p>.</p><p><strong>Heat Sink Issues:</strong>Â Annie mentioned that Phoenix 11 has had issues related to heat sinks, which has led Sunita to prioritize training clusters first. This prioritization is reflected in the shared schedule.</p><p><strong>Update Process Flow:</strong>Â Annie and Chloe discussed the process flow for updating the IB switch and GPU baseboards, considering the possibility of doing these updates in parallel to minimize downtime.</p><p><strong>CRD and OFR Dependencies:</strong>Â Anastasia and Oswaldo explored the dependencies between CRD updates and nodes coming out of OFR, emphasizing the need to understand the sequence of updates to avoid potential issues.</p><p>.</p><p><strong>CRD Update Timing:</strong>Â Anastasia and Oswaldo discussed the timing of CRD updates in relation to nodes coming out of OFR. Anastasia mentioned that CRD updates would happen after nodes are out of OFR, and she is investigating the dependencies with the mods team.</p><p>.</p><p><strong>Flow Clarification:</strong>Â Oswaldo clarified that there are two flows: one where nodes are updated in OFR if there is a firmware mismatch, and another where nodes are updated in production if there is no mismatch. The sequence of updates in production needs to be clarified.</p><p>.</p><p><strong>Dependency Concerns:</strong>Â Oswaldo raised concerns about the potential fallout from updating CX7 firmware before CRD, referencing past issues and the need to consult with engineers to understand the root cause.</p><p><strong>Flow Clarification:</strong>Â Oswaldo clarified the flow for nodes coming out of OFR, detailing the scenarios where nodes would be updated in OFR or in production, and the importance of understanding the sequence of updates.</p><p>.</p><p><strong>OFR Flow:</strong>Â Oswaldo explained that nodes coming out of OFR would either be updated in OFR if there is a firmware mismatch or updated in production if there is no mismatch. This distinction is crucial for planning the update sequence.</p><p>.</p><p><strong>Update Sequence:</strong>Â Oswaldo emphasized the need to understand the sequence of updates, particularly whether CRD or OS updates should happen first, to avoid potential issues. He suggested consulting with the PF team for clarity.</p><p><strong>Potential Issues with Update Sequence:</strong>Â Oswaldo raised concerns about the potential fallout from updating CX7 firmware before CRD, referencing past issues and the need to consult with engineers to understand the root cause.</p><p>.</p><p><strong>Past Issues:</strong>Â Oswaldo referenced past issues where updating CX7 firmware before CRD led to a large fallout. He emphasized the need to understand the root cause by consulting with engineers who were involved at that time.</p><p>.</p><p><strong>Dependency Clarification:</strong>Â Oswaldo and Chloe discussed the need to clarify whether CRD has a dependency on OS or vice versa. Chloe suggested checking the list of priorities to determine the correct sequence of updates.</p><p>.</p><p><strong>Action Items for Clarification:</strong>Â Annie and Oswaldo agreed on the need to clarify the update sequence with the PF team and to review the list of priorities to ensure the correct order of updates.</p><p><strong>Diagnostic Flow and Time Estimation:</strong>Â Annie and Oswaldo discussed the complexity of estimating the time required for updates, considering the diagnostic flow and the need to consult with Sunita for a more accurate estimation.</p><p>.</p><p><strong>Time Estimation:</strong>Â Annie and Oswaldo discussed the complexity of estimating the time required for updates, considering the diagnostic flow. Oswaldo mentioned that the duration of the maintenance should come from the team doing the hardware repair, and they need to consult with Sunita for a more accurate estimation.</p><p>.</p><p><strong>Diagnostic Flow:</strong>Â Oswaldo explained that the diagnostic flow involves several steps, including detecting firmware mismatches and updating nodes accordingly. The time required for these steps needs to be considered in the overall time estimation.</p><p>.</p><p><strong>Training Cluster Update Flow:</strong>Â Send a copy of the process flow to Oswaldo for him to edit and branch into two buckets. (Annie)</p><p>.</p><p><strong>Diagnostic Duration:</strong>Â Ask Sunita how long the diagnostics part will take for nodes going through OFR. (Annie)</p><p>.</p><p><strong>Pilot Fish Agent Priority:</strong>Â Check the list of priority for Pilot Fish agents to determine the sequence of updates for nodes coming out of OFR. (Chloe)</p><p>.</p><p><strong>Open AI Maintenance Notification:</strong>Â Determine the date to notify Open AI about the start of maintenance and ensure all questions are resolved before presenting the plan. (Annie)</p><p>.</p><p><strong>Fault Code Optimization:</strong>Â Discuss with the DC OPS team the possibility of forcing nodes into a specific fault code to ensure Coolville runs during the repair process. (Sean)</p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://azhou35.github.io/my-digital-garden/js/graph.afdb02e537635f9a611b53a988e5645b.js></script></div></div><div id=contact_buttons><footer><p>Made by anniez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2026</p><ul><li><a href=https://azhou35.github.io/my-digital-garden/>Home</a></li><li><a href=https://twitter.com/azhou35>Twitter</a></li><li><a href=https://github.com/azhou35>Github</a></li></ul></footer></div></div></body></html>