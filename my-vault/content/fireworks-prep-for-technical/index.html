<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=description content="technical conversation/experience llms/inference optimization levels how r they used why r they used scheduled w engineering leadership &ldquo;The technical interview will cover your ability to interface with technical stakeholders at Fireworks, including how you&rsquo;d think through potential solutions."><title>fireworks prep for technical
</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://azhou35.github.io/my-digital-garden//icon.png><link href=https://azhou35.github.io/my-digital-garden/styles.591589daec716a7d5287f8d56c2c091e.min.css rel=stylesheet><link href=https://azhou35.github.io/my-digital-garden/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://azhou35.github.io/my-digital-garden/js/darkmode.111b0c7178f4cf301c69a167d6c795e4.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script src=https://unpkg.com/@floating-ui/core@0.7.3></script><script src=https://unpkg.com/@floating-ui/dom@0.5.4></script><script src=https://azhou35.github.io/my-digital-garden/js/popover.37b1455b8f0603154072b9467132c659.min.js></script><script src=https://azhou35.github.io/my-digital-garden/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script><script src=https://azhou35.github.io/my-digital-garden/js/clipboard.25155053855f45fdc48fd92540bcebc9.min.js></script><script>const BASE_URL="https://azhou35.github.io/my-digital-garden/",fetchData=Promise.all([fetch("https://azhou35.github.io/my-digital-garden/indices/linkIndex.5c028caf57436319105eed1adcb927c7.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://azhou35.github.io/my-digital-garden/indices/contentIndex.96fe211259d9d155b3a98848d7389e77.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL(BASE_URL),s=n.pathname,o=window.location.pathname,i=s==o;addCopyButtons(),addTitleToCodeBlocks();const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!1;drawGraph("https://azhou35.github.io/my-digital-garden",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://azhou35.github.io/my-digital-garden",!0,!0)},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/azhou35.github.io\/my-digital-garden\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J")}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script><script defer src=https://azhou35.github.io/my-digital-garden/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://azhou35.github.io/my-digital-garden/>ü™¥ anniez</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg>
</label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>fireworks prep for technical</h1><p class=meta>Last updated
Unknown</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#virtual-cloud>Virtual Cloud</a></li><li><a href=#tradeoffs>Tradeoffs:</a></li><li><a href=#past-technical-solutions>Past Technical Solutions</a></li><li><a href=#batch>Batch</a></li><li><a href=#planned-maintenance-api-on-baremetal>Planned Maintenance API on BareMetal</a></li></ol></li></ol></nav></details></aside><ul><li>technical conversation/experience<ul><li>llms/inference</li><li>optimization levels</li><li>how r they used</li><li>why r they used</li><li>scheduled w engineering leadership
&ldquo;The technical interview will cover your ability to interface with technical stakeholders at Fireworks, including how you&rsquo;d think through potential solutions. I&rsquo;d be prepared to talk about your past technical work here too.&rdquo;</li></ul></li></ul><a href=#virtual-cloud><h3 id=virtual-cloud><span class=hanchor arialabel=Anchor># </span>Virtual Cloud</h3></a><ul><li>VPC - dedicated isolated environment within a public cloud w virtual networking</li><li>Virtualization Foundations Virtual Machines (VMs) are software-defined computers that emulate hardware, running their own OS and encapsulating compute workloads Identical Cloud Oracle . Hypervisors manage multiple VMs on shared hardware, abstracting compute, memory, and storage to enable flexible allocation</li><li></li></ul><a href=#tradeoffs><h3 id=tradeoffs><span class=hanchor arialabel=Anchor># </span>Tradeoffs:</h3></a><ol><li>latency vs throughput</li><li>performance vs cost</li><li>performance vs reliability<ol><li>optimizing for cluster uptime to inimize disruption to model training</li></ol></li><li>scalability vs reliability</li><li>flexibility vs optimization</li></ol><a href=#past-technical-solutions><h3 id=past-technical-solutions><span class=hanchor arialabel=Anchor># </span>Past Technical Solutions</h3></a><a href=#hpc-copilot-for-workflow-orchestration><h4 id=hpc-copilot-for-workflow-orchestration><span class=hanchor arialabel=Anchor># </span>HPC Copilot for Workflow Orchestration</h4></a><p>‚ÄúAt a high level, I worked on designing an <strong>AI assistant to orchestrate HPC workflows on Azure Batch</strong>. The problem we tackled was that managing HPC infrastructure in the cloud is complex‚Äîusers have to provision VMs, configure environments, schedule jobs, and manage resources, which is especially challenging for tightly coupled, compute-intensive workloads like genomics.</p><p>Our solution uses <strong>specialized LLM modules</strong> for distinct tasks‚Äîenvironment setup, task creation, and VM configuration‚Äîso that users can interact in natural language while the assistant generates structured, executable workflows. We applied <strong>prompt engineering</strong> to ensure outputs are precise and <strong>RAG (retrieval-augmented generation)</strong> to ground the model in Azure Batch documentation, improving accuracy.</p><p>The result is a tool that <strong>lowers the barrier to entry for cloud-based HPC</strong>, automating complex steps while preserving flexibility and efficiency. From a PM perspective, I drove the architecture design, defined module responsibilities, and collaborated closely with engineers to explore trade-offs between automation, performance, and resource utilization.</p><ul><li>Engineering tradeoffs:<ul><li>API Engineering Limitations</li></ul></li><li>Structure artifacts - JSON templates to be consumed by the Batch APIs<ul><li><ul><li><strong>Environment Setup Module</strong>: Installs dependencies, pulls container images, uploads data to storage.<strong>Task & Job Creation Module</strong>: Converts workflow scripts into Azure Batch tasks, defining inputs, outputs, and execution order.<strong>VM & Node Configuration Module</strong>: Suggests optimal VM SKUs and number of nodes based on workload requirements.</li></ul></li></ul></li></ul><ol><li>Proof of Concept with healthcare solutions<ol><li>Research labs</li></ol></li></ol><a href=#batch><h3 id=batch><span class=hanchor arialabel=Anchor># </span>Batch</h3></a><ol><li><p>driving improvements to compute scalability for enterprise customers running large-scale batch workloads. We started noticing recurring feedback from high-throughput customers‚Äîparticularly one like <strong>WTW</strong>, a major actuarial firm‚Äîregarding <strong>slow job startup times</strong>, even when warm nodes were available</p><ol><li>reduce <strong>cold start latency</strong> for jobs, while keeping costs under control. I needed to <strong>rethink the Warm Pool feature</strong>, which pre-provisions compute nodes to reduce startup time, but had platform limitations that made it slow, inflexible, and costly for production users.<ol><li>At the time, the scheduler would spin up new VMs even if deallocated ones were sitting idle, because it treated them as unavailable. The engineering work was about changing state handling</li></ol></li><li>customer requirements:<ol><li>balance performance vs cost
automation - use available warm nodes instead of spinning up old ones</li><li>wanted to quickly reuse pre provisioned nodes</li></ol></li><li>short term solution:<ol><li>Let customers <strong>pre-create compute nodes in an ‚Äúoffline but ready‚Äù state</strong> ‚Äî this was something Azure ML already used internally, so we pushed to make it available more broadly.</li><li>Update our scheduler to <strong>automatically prioritize warm nodes</strong> before provisioning new ones.</li></ol></li><li>what i actually did:<ol><li>partner with engineering and platform teams<ol><li>short term:<ol><li><ul><li>Repurpose <strong>internal Azure ML technique</strong> ‚Üí allow <strong>pre-created ‚Äúoffline but ready‚Äù nodes</strong></li></ul><ol><li>technical details: understood the bottlenecks for number of standby pools</li></ol></li></ol></li><li>long term:<ol><li><ul><li><ul><li>Worked with <strong>Azure VMSS team</strong> on <strong>Standby Pools</strong>: near-instant activation (~50 VMs in 40s), plus ODCR for reserved capacity.</li></ul></li></ul></li></ol></li></ol></li></ol></li><li>tradeoofs:<ol><li>performance vs cost - storage vs fast startup</li><li>automation vs control</li></ol></li><li>outcome: public preview</li></ol></li><li><p>Common tradeoffs:
1.Cost optimization vs time efficiency
also work with cyclecloud
on prem overprovision for peak usage
genomics researchers have often complained about unnnecessary spend
performance vs flexibility</p><ol><li>GPU limitation</li><li>Tightly coupled HPC workloads demand ultra-fast, low-latency networking (e</li><li>Loosely coupled workloads benefit from cloud scale, but may not fully utilize specialized hardware, leading to potential inefficiencies
Technical Guide:
<a href="https://microsoft.sharepoint.com/:w:/r/teams/BigComputeChampions/_layouts/15/Doc.aspx?sourcedoc=%7B04CD7EAC-40E4-46F0-8996-194E96997F32%7D&amp;file=Technical-Guide-to-Onboarding-on-Azure-HPC.docx&amp;action=default&amp;mobileredirect=true&amp;share=IQGsfs0E5EDwRomWGU6WmX8yAQiKow9ntGwBj4_pLb4APlA" rel=noopener>Technical Guide to Onboarding on Azure HPC.docx</a></li></ol></li></ol><a href=#node-state-management><h4 id=node-state-management><span class=hanchor arialabel=Anchor># </span>Node State Management</h4></a><ol><li>High level concern from OpenAI is that they wanted their nodes as soon as they were updated - in tension with our current system - also kept landing vms during planned maintenance times<ol><li>Our level of support was highly manual and we&rsquo;ve never worked with this user scenario<ol><li>Evaluated options:<ol><li>node locking</li><li>node pinning - can we pin these jobs to specific nodes?<ol><li>at the VMSS level</li></ol></li><li>node &ldquo;ua&rdquo; state</li></ol></li></ol></li><li>‚ÄúI worked on improving planned maintenance for OpenAI‚Äôs dedicated GPU clusters. Historically, every update required taking the entire cluster offline, even if only part of it was being updated, which created costly downtime for OpenAI and inefficiency for us.‚Äù ‚ÄúThe underlying issue was that nodes could only be released back to OpenAI once the entire cluster finished. Even if 80% of nodes were healthy and ready, they sat idle until the last 20% were updated. This was due to the lack of a mechanism to lock, track, and gradually release nodes safely.‚Äù ‚ÄúI explored different approaches with engineering partners:</li></ol></li></ol><p>‚Äì Timestamp-based availability (delaying release of nodes until they were verified).</p><p>‚Äì Introducing a new ‚Äòhard unavailable‚Äô state in the fabric allocator.</p><p>‚Äì Node locking: programmatically locking nodes under update so they can‚Äôt be allocated, and releasing them as soon as they pass verification.</p><p>I worked with the allocator and VMSS teams to assess trade-offs ‚Äî short-term feasibility, engineering lift, and operational risk.‚Äù</p><ol><li>Streaming node-by-node updates for FW<ol><li>Work w the FW team on how we can blast these updates</li><li>Less of an engineering problem than a technical implementation</li></ol></li></ol><a href=#planned-maintenance-api-on-baremetal><h3 id=planned-maintenance-api-on-baremetal><span class=hanchor arialabel=Anchor># </span>Planned Maintenance API on BareMetal</h3></a><ul><li>OAI is actually mving to a baremetal use of cloud to cut out virtualizations altogether</li><li>a recurring request is for full customer control over their maintenance updates - right now its highly disruptive with human oversight</li><li>before these requests were lost on deaf ears but i bridged the gap to Working w our maintenance orchestration platform team, OneDeploy, to build a customer-controlled API for all supercomputers.</li><li>The gap is that customers need <strong>more control over update timing, visibility into impact, and failproof recovery</strong>, but existing processes don‚Äôt support selective rollout or rapid, safe cluster-wide updates</li><li>The Fairwater API is built around a new resource provider (RP)<ul><li><ul><li><strong>Stop BMI API</strong>: Halts the node without deallocating it.</li></ul></li><li><strong>Reimage BMI API</strong>: Refreshes the node while in a stopped state.</li><li><strong>Restart BMI API</strong>: Brings the node back online post-update.</li></ul></li><li>These APIs are coordinated via the <strong>AzNOM API</strong>, which notifies the control plane (e.g., Anvil) before rebooting.</li><li>Work across engineers who own these different updates</li><li>Gaps:<ul><li>Validation has only been done on VM nodes. BMI testing is pending due to lack of healthy stage nodes</li></ul></li></ul><p>notes:</p><ul><li>fireworks is fundamentally a driver that optimizes for the latest model performances for the cloud</li><li>hyperscalers throw more money and ppl at something</li></ul><p>Small expert models as key components of the future of AI systems</p><p>Open AI has requested access to telemetry and device CLI to accelerate debugging and diagnostics. The request covers the following:¬†</p><ul><li><p>Some switch configurations (e.g. SRv6 routes) defined by OAI¬†</p></li><li><p>APIs to disable suspect switches/links¬†</p></li><li><p>ssh read-only access¬†</p></li><li><p>self-serve packet capture¬†</p></li><li><p>Direct telemetry streams for counters, syslogs (i.e. not through kusto)</p></li></ul></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://azhou35.github.io/my-digital-garden/js/graph.afdb02e537635f9a611b53a988e5645b.js></script></div></div><div id=contact_buttons><footer><p>Made by anniez using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2026</p><ul><li><a href=https://azhou35.github.io/my-digital-garden/>Home</a></li><li><a href=https://twitter.com/azhou35>Twitter</a></li><li><a href=https://github.com/azhou35>Github</a></li></ul></footer></div></div></body></html>