---
title: "chat '25 analysis"
---

### Email
**Justin emails you when friendship needs to be consciously re-authored**—when proximity is about to change, when attention slips, or when he wants to convert “we hang” into “we mean.”


### Articles
1. limits of measurement
	1. _What cannot be evaluated still governs outcomes_
2. Interior Life vs. External Systems
	1. 
3. Place still matters - belonging 
	1. what places make you feel like urself
		1. third spaces
		2. urban memory mapping
4. Craft, Practice, and Thinking in Public

![[bookmarks_over_time.png]]
AI is a complex system; we need evaluation, but the field is young and the “what should we measure?” question is still contested
**metrics lag**, health definitions are political, and “truth” is partly tacit.

If AI is (1) hard to evaluate, (2) physically constrained, and (3) economically distorted by accounting and coalition advantages, then the most important questions aren’t “what can models do?” but:
- **How do we decide what’s safe/healthy when we can’t measure the right things yet?** [The Point Magazine](https://thepointmag.com/examined-life/complex-systems/)
- **What are the real bottlenecks (power, chips, replacement cycles) that shape the future?** [SITUATIONAL AWARENESS - The Decade Ahead+1](https://situational-awareness.ai/racing-to-the-trillion-dollar-cluster/)
- **Who gets locked in / locked out while the cost story is still fuzzy?**[](https://blog.citp.princeton.edu/2025/10/15/lifespan-of-ai-chips-the-300-billion-question/)

incentives reward novelty (new features, new trains, new posts) while starving stewardship (maintenance budgets, maintainer time, documentation, knowledge hygiene).
**framework essays** that give you _names for modern feelings_
prefer writing that’s **half narrative, half systems model** (a concrete vignette → a general mechanism)
If evals are contested _and_ results aren’t stable, how do we make high-stakes decisions without lying to ourselves with a single number?
- metrics vs signals