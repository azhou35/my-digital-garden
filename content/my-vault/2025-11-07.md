---
title: "2025-11-07"
---

Script for RPMs

Quick intros - Kenny a[]()nd I work closely to bringing up new capacity and keeping it healthy, Jos works on scheduling and how to make compute accessible to researchers. 

We've been running an effort on better usability on flex compute and overallocation and wanted to chat with you guys as the RPMs.  

Researchers are often told they have _X healthy GPUs_, but due to hardware health issues and **overallocation**, those GPUs don’t truly exist — so jobs fail to start, breaking carefully planned training schedules. Because many researchers aren’t aware overallocation is happening, they expect immediate scheduling, which creates frustration and misaligned expectations.

So for example, in a cluster of 100 GPUs, prob 85% are actually healthy. But we've allocated folks up to 95% and up. So researchers put critial jobs on 95 GPUs and run into issues -> crashes :( 

We've introduced flex compute previously but there's always been ambiguity on how to actually get your workloads to schedule. 

Generally we want to get to a more elastic compute and guarantee that critical jobs are scheduled. This entails improving usability of flex and also increasing the amount of felx compute, and also making sure high critical jobs are scheduled appropriately. 

So the first step we did was roll out the latest flex changes -  ppl can directly target flex. 

Slowly making flex more usable but we also want to have more of it in the fleet. To that end we want to get to a world where we adjust the current quotas to reflect reality of truly healthy GPUs, and keep a buffer available. Any GPUs that are above get pulled into the flex pool.

It has to be a mutual effort so the implementation of this is where we would appreciate your help / feedback. 

X Y Z

The end goal is that we want to make flex really

what workloads can be moved to flex 
and 