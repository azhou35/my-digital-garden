---
title: "planned maintenance"
---

solution - 
let agree w every provider 
what is the data contract

step #1
ingest every spreadsheet 
analyze every spreadsheet - get the common fields that we cna use and serve a table

create a table in databricks w data script
cristian will read a pipeline that will generate a table from databricks

step #2 
move the data to snowflake 
tell sigma to use this data in this table


identify what are the attributes
create the etls

benefit of having this finisher
new providers will tell them this is wht we need

define the attributes
review that and create the schema
and check the mapping
if this attribute 
and this is located in this 
infra we have rn is enabled to run the etl 

what entails that something is in maintenance 
if this if something is dropped and 
couple of days next week

cristian doesnt control 
- cant support how sigma reads froms sigma
supply team 
- they do all of our contracts 
- they ensure that this tranche and check our telemetyr 
- that process of consoldation 
- for them its rlly hard
- bc once we bring up the nodes, a node can move one cluster to another 
- attach contract id for eveyr node 
- do bring the cluster id for each contract
- irrespective of the movement across the clusters
	- these machines are attached to the contract
- who can help on incorporating data 
- the data is in sigma 
- tie that on sigma 
when we do the bring up 
- incorporating the fleet into the nodes in the first place
	- https://app.sigmacomputing.com/open-ai-azure/workbook/OpenAI-GPU-Single-Source-of-Truth-go-gpu-ssot-1zRqIrPg0YtB7FS7RNKRg5?:nodeId=mRUSpN2vNT
- what theyre doing is complicated
- not sure if 100% is in oru fleet 
- david is down to do the backfil

common attributes
meet on monday

narwhal
beluga
boto
caas-dc-0
minke
orca
susu
whale