---
title: "2025-11-05"
---

strategy for rpms

----- 
1) our goal
	1) provide researchers with stable and predictable access to compute esp for long-running jobs
	2) quota assignments to reflect what is actually reliably available in a cluster over time 
2) the problem we want to solve:
	1) today clusters appear to have enough quota but the # of healthy nodes can vary from week to week 
	2) teams have been allocated more quota than healthy gpus to back it 
	3) silent failure modes 
	4) visibility problesm for why they have quota but cant use it 
3) tooling implementation
	1) in the future we want to introduce a buffer-based quota policy tied to cluster healthy 
	2) where zoku quota will automatically align to healthy node count
	3) when cluster has more healthy nodes than SLA buffer, excess capacity flows into flx pool
	4) *this is not removing compute from teams* since everything is divertede to flex 
4) explanation of the tools / knobs 
	1) jos to explain flex compute
5) the ask from rpms
	1) socialize the shift to stable backng capacity 
	2) how to treat flex as real compute 
	3) will start with clusters with healthy headroom to build confidence 

---
log
- quarantined 
	- https://engine-manager-web.engine-manager-0.internal.api.openai.org/clusters/c227 
Yeah, from my observations on call last week, majority of capacity issues are allocation problems. Some of the bare metal clusters, including sodium, aluminum, and tiger are suffering because we're not keeping them up to date.The trade-off on micromanaging the 1 to 5% of capacity that we could recover with some concerted effort is giving up new SKU/new CSP work or reducing collaboration with frontiers in a few places (that partially overlap with our interests)Â (edited)

question - when i adjusted quota to this one team theres another team that grabbed the extra quota 
-> what do we do if another person joins and takes the quota 

https://oai-research-ah.slack.com/archives/C07CJT8J1H6/p1760648613839379 

Flex currently is unreliable because any other quota overscheduling also automatically uses any free capacity in the cluster - and since there's usually more jobs created than we have capacity in a cluster, flex tends to sit at 0 availability. That will change with the above proposal

The goal is to have flex be a much more useful general compute pool

-> visible maintenances
-> sevs
![[Screenshot 2025-11-05 at 1.21.15 PM.png]]
tiger quota - 
flex: 
36+75 in flex 

find product-research account 


product-research 
- flex 
	- 75
	- 32
	- 4
		-=> total = 75
- h100 - 361 total 
	- 319 healthy 
	- 345 assigned
	- 310 allocated
	- = 35 lower 

let me walk thru where we'd make cuts and what would make sense - 
