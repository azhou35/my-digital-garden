---
title: "AI Safety ourse"
---

[Future of AI - Beyond chatbots: the expanding frontier of AI capabilities](https://course.aisafetyfundamentals.com/future-of-ai?unit=1&r=WK7RYB)
[Compute Cluster | CAIS](https://www.safe.ai/work/compute-cluster)
[6.3: Fairness | AI Safety, Ethics, and Society Textbook](https://www.aisafetybook.com/textbook/fairness)

**What does it mean to “form your own views”?** I mean something like forming a detailed model, starting from some basic and reasonable beliefs about the world, that gets you to a conclusion like ‘working on AI alignment is important’, or ‘this research direction seems like it might shift the needle on AI-induced x-risk’, or ‘[Power-seeking AI poses a decent chance of extinction](https://www.lesswrong.com/posts/HduCjmXTBD4xYTegv/draft-report-on-existential-risk-from-power-seeking-ai)

Early in your career (for the first few years out of undergrad, at least), your focus should be on doing things where you can grow and become excellent. You can ask yourself (and others) where you’re likely to grow the most, and then go there. That might be alignment organisations, and it might not. Growth is largely a function of your environment and the mentorship available to you. The vast majority of good mentorship can be found outside of alignment, and alignment is heavily mentorship-constrained

Though there is nuance in ‘capabilities’: working on improving Bayesian inference approximation (useless-to-maybe-helpful for alignment) is very different from scaling up large language models (probably pretty bad)

[Being the (Pareto) Best in the World — LessWrong](https://www.lesswrong.com/posts/XvN2QQpKTuEzgkZHY/being-the-pareto-best-in-the-world)

- AI Interpretability Ethics and Implications
- AI Ethics with Allen Lab for Democracy Renovation (more information on the joint fellowship [**here**](https://cyber.harvard.edu/getinvolved/fellowships/bkc-allen-lab))
- Agentic AI Protocols and Risk Mitigations
- Artificial General Intelligence Futurecasting and Policy Development
- Tech, Tools, and Practices for Improving University Discourse
- Safety Solutions for Social Media

You can divide career aims into three categories: (i) impartial positive impact, (ii) personal priorities, and (iii) other moral values. We’d encourage you to make your own definition of each.
[Working List of Hard Problems in AI - AI2050](https://ai2050.schmidtsciences.org/hard-problems/)
### Solved what it means to be human in the age of AI, or John Maynard Keynes’ problem when he noted, “Thus for the first time since his creation man will be faced with his real, his permanent problem— how to use his freedom from pressing economic cares, how to occupy the leisure, which science and compound interest will have won for him, to live wisely and agreeably and well.”

Steve believed that if you give great tools to talented people, they will use them to make wonderful things. But tools are more than the devices in our hands: they’re the skills we develop, the lessons we learn, and the connections we cultivate. 

That’s the mission of the SJA Fellowship: to support promising young people in their creative, professional, and personal development. Through this yearlong, nonresidential program, SJA Fellows receive a stipend to pursue their ideas, a nationwide community of peers, individualized mentorship, and exposure to bold creative practitioners working across disciplines.
