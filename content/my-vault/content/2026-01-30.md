[[inequality in labor 01-30]]

```markdown
date: 2026-01-30
title: 2026-01-30 todo
tags: 
   - productivity 
```
### P0 
- [ ] Buy toilet paper
- [ ] Buy scallion Pancake 
### P1
- [ ] Clean apartment 
- [ ] Return Chair 
- [ ] Pay bills 
### P2
- [ ] Fix app 
- [ ] 


## HPE
HPE 
- Thursdays at 10AM 
- A lot of asks around log collection 
- Have to think about for CW 
- With VMs they are able to take back instance that is back under their parlay 
- For BM - they cant get back the instances - they’re under our control - so they can’t run any tests/commands 
- As a result: if we send them an instance they can’t run tests - they need logs
- With HPE:
	- DCTs are not well trained 
	- They ask for all the logs unrelated to a certain issue
	- They require all our logs 
	- What is the big solution here?
	- They need to train their DCTs better lol 
	- Don’t understand the diff on what can be actioned by DC team vs our team 
	- Figure out how to run field diag 
- [P2] CW: can plug in usb and run diag tests
- CW needs field diagnostic logs for GB200s 
- Enabled back in fall - test needs exclusive access to NV models
- Aka kill system modules/system libraries
- Test initialization would not work - long queue of long running tests [hrs long, rsource intensive]
- Need to turn it back on 
	- What is the impact?
	- They perform guest work when they do repairs 
	- By this quarter - get it at least running 

Liz - action items and calling out "drafting a message"


## Sync w Ricky
covering for SImon 
interaction w Simon / scheduling 
things that can be improved

MAI 
- request GPUs from Fleet Team in MAI 
- handle acquiring the GPUs 
sprint cycles 
- 7 weeks to think of what to build 
- what you would work on 
- work on some product teams
	- FIle uploads
	- OpenAI x Microsoft relationship
- more intense than here
- a lot of devs in China
	- they werent tented
	- couldnt do design reviews
	- go check OpenAI and IP 
- startuppy culture 
- outside engineer
	- engineers that work at both OpenAI and Microsoft
	- FDE 
		- in the org chart
		- that person would hosts office hours w OAI 
		- its also the culture
- OAI 
	- wasnt actively applying that fit ur bg super well 
	- at GCP 90% of career 
	- automation - creating a version of global quota
	- fleet management
- GCP 
	- shared resources
		- clean in the applied side of things 
	- research 
		- not as clean
		- researchers are pinned to how much capacity they have 
- when we take GPUs 
	- is it from GPU available 
	- 1 workflow 
		- SImon wants to do some allocation that will shift a bunch of stuff 
		- and he knows my maintennace has maintenance schedule
- when ur bringing down 
engineering team will build tooling for 
use case:
- some other moves 
- some other ppl want to 
- level of configuration 

whenever u do these maintenances

## Daily Ops Call 2026

![[Screenshot 2026-01-30 at 1.46.29 PM.png]]

Kanna on API:
- Self-serve maintenance AP
- Works for all MSFT tested compute updates
- updates on individual nodes

next iteration:
- nvl update 
![[Screenshot 2026-01-30 at 1.48.23 PM.png]]
What's the fastest that we can imagine
