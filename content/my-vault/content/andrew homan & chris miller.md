---
title: "andrew homan & chris miller"
---

where is value going to accrue across the stack?
cloud providers going deep in lines

finding areas prev ignored by chips are being prioritized

interesting emerging players in semi conductors - a lot more incumbents
priv companies > public companies

bubble - capex training 
mismatch between utilization and investment 
wherease today: spending done by hyperscaler (relative to history) - capex is in line 
sustainable level where u could double capex and businesses will be fine 

apple - making their own chips for iphones
other companies talk about "edge ai"
nvidia dominates data center but edge is left
- power usage of nvidia gpus are high 

microsoft / amazon are at a scale where they dont move that quicky
coreweave had        h100s out in march 2023 - when u coudnt spin up a h100 until 6 months later
nimble startups can move quickly and align w a company to create a lot of value 

if latency matters - u want compute on the device 
power - ur building to handle peak load - but are there creative ways to incentivize folks to bring peak level down?

3 pain points:
1) getting design tools
2) getting ip 
3) foundry piece/broader manufacturing
is there a way to work w a player in each bucket and ease the burden for these startups

nature of the ppl building things:
* exp running hardware 
much diff than younger foundes

lay of the land 

key unlocks: memory architecture
memory is too far from processor
-> aka I/O slows down innovation 
can lower cost of compute

gpu performance is outpacing networking/memory piece

scale comes from 3rd party foundry
ai model research - few ppl really seem to matter for foundational ai 
