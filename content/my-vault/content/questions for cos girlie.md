---
title: "questions for cos girlie"
---

- "How dooes the gen ai workstreams (off the shelf data, evals-as-a-service, project spec) fit into Alexandr's broader vision for Scale over the next 2-3 years?"
- - "How would you prioritize between these three major workstreams if resources were constrained?"
- **Re: seems like scale is taking a big bets to define  gen ai esp evals - whats the pre mortem - what keeps you up at night**
- How do you see growth internally?
- Whats kept you at scale for the past two years? 
- "What does success look like for Scale in the foundation model space as the market matures?"
- "How is Scale thinking about the competitive landscape as more players enter the AI data/eval space?"
	- E.g. Handhsake AI, Snorkel, Mercor
- - "How does Scale maintain its competitive moat as AI companies potentially try to build these capabilities in-house?"
- - "Scale is moving from custom data projects to standardized products. What do you see as the biggest challenges in that transition?"
- 
ai optimist
using our internal research
- infra for training 
- data
- data 
sophisticated interal data team

evals to rl data
new crop

- on the topic o f data
	- how do we translate from research -> product
	- evals and llm showdown
- scales research led 
	- data
	- scale does its best forming research partnerships
	- developing data
- scale have a position 
- synthehtic data

425 247 8559
Linda Gong




tracking 
generative ai team 
services company to a product company
1. OTS Data Platform
2. Evals as service
3. Project specifications & Intake 

how scale can keep its moat:
- platform strategy
- move up value chain
	- ai infra stack - - Data layer (OTS platform) + Evaluation layer (auto-evals, Scale Showdown) + Process layer (project specs)
- data economies of scale 
- own the evaluation layer


**The "Commoditization Trap"**

- Moving to standardized products risks making their expertise less differentiated
- If OTS data works, why wouldn't customers eventually build it themselves?
- Scale might be training their future competitors by standardizing their processes

by pass storage and use it via avent hub
use it aggregation
1.  do aggregation at kusto level
2. use event hub to feed into streaming analytics job
3. kusto 

getting data into stream analytics

ignore limitations
handover docs

Set up a call next week

cycledev
- good feeder for what we need to do