---
title: "2025-05-27"
---

1. LEGORA 
2. Send resume 
NFZ lift experience is highly manual - there have been huge gains since the first time we've lifted nfz, with some of the product operations we've improved previously, we return the cluster to customer earlier each time

yk earlier in the month we essentially had to babysi

prep for meeting
I'm presenting our progress on H100/H200 maintenance optimization - covering the full stack from host updates through firmware, datacenter, and networking operations.
- Wont dwell too long on this as Diego has presented on O(1) previously but 
- It remains high priority to ensure we're driving towards the north star of O(1) operations time OAI expects to drive down this maintenance window 
- We've made significant headway in some of these operations that i want to highlight - e.g. node repave and reboot, for repave, we've driven them down from 12 hrs to 2 hours per 600 nodes, and reboot a similar reduction from 12 to 1.
- These are significant 80-90% improvements
- We've identified and are addressing bottlenecks in CRD operations - our current long pole - e.g. nsd starvation, which also affects the host os updates
- next steps driven by diego is trying to see if we can get access to buildout cluster to do some drills to actually run tests and see if we can do target time.
- This will give us real-world data to verify our optimization strategy
- NSD starvation acts as a bottleneck by limiting the number of threads available to manage node operations, leading to delays in polling and processing node states. By optimizing thread allocation and improving polling efficiency, these bottlenecks can be mitigated, allowing for faster and more efficient node operations.

- while not updates themselves, repave is used to completely wipe the OS and restore it to resolve issues, reboot restarts the node when node encounters unknown failures. All important in planned maintenance ops
- Certain updates like CRD which is the long pole have dependencies on 
- Address common bottleneck of NSD Thread Starvation by reducing polling intervals and timeouts for unresponsive node, which enables nodes to roll out without 300 nodes/hr constraints.
- Which is reducing time for CRD

whoever gets there first to defining the behavior 
gets to define whos right or wrong 

reach out to mitra then about kpi
1. reach out to linda park
	1. governance review to make sure we have everything in line
2. sub clean up 
	1. pretty good shape 
	2. some kind of process for scanning regularly and alerting and individuals that things are not tagged
3. wanna make sure we clean up any test resources
	1. use the workspace
4. cyclecloud data

need to find someone elses mitra team 


carter meeting

what are some the bigst gaps
2 things


**Brandon call**
bg:
how was ur mdw?
where u calling from?
i can start with a quick backround
- microsoft for a year, ai supercomputing infra for openai
- microsofts been great to see trainng at scale but
- looking into startups and rlly trying to talk to a wide range of ppl who have moved from microsoft pm to startups specifically 
- been really seeing traction on the asic chip side 
- groq, etched, cerebras
- start an open convo to understand
	- what drew u towards cerebras
	- when u knew it was the right time to jump
	- evaluating which asic startup to join

brandon 
release management 
validation
look for change sooner rather than later
mentor had joined
building out cloud and 
buildnig out console experience
interviewed at scale ai

opposite end of spectrum
coreweave
- whend u know it was right time to switch
- - howd u prep urself for the time
- advice for mentorship
- day2day as a inference stack
internal network
