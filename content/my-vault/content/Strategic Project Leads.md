---
title: "Strategic Project Leads"
---

genai side of Scale 
support AI model builders out there 
ChatGPT, LLAMA - work w them from training data pov
26% of growth
company just to execute on this growth
within company - they solve problems within the Q
AI models - always learning more
Scale creates the data for students to learn 
Build what the model builder wants them to do
a model builder comes to us and 
have a growth team that goes out in the world and finds the contributors who are SMEs in math and create datasets in that sense
math olympiads / phds in math
brings them into outlier
ppl are inthe platform
SPL are managing these project teams contributing to this
can be 10 - 1000
managing these teams of contributors
how to help them produce the highest qualityd ata for customer
creating systems
finding efficiencies and making it better
starts all the way from starting with the math proj
maybe these ppl dont know
building benchmarks
understanding quality of data
are we building this 
Growth team finds ppl in the world 
creating datasets  on time
delivery relationship w client
u are the person between contributor and 
think about the tooling that Spl uses and the contributors
tooling is internal for SPL
if u see anything that can be improved you talk directly w PM
appreciate technical background
platform is like a gpt interface
this is how contributors interact w data 
technicality - someone who can solve poblems
kpis for the role - quality of data + delivery of data in time 
third kpi - new revenue generation 
unlocker of revenue of scale 
unlimited amount of demand for this data
if project goes quickly and good can go work on more clients
unlocks a lot of revenue
ppl within the first few projects can actually unlock money for scale 
SPL can average 65-80 hours
creative writing / history 

role was created last year
50-60 ppl 
directly aligns wit revenue of company
dont have a limit for ppl 
how much ppl can we hire can 
GPUs chips - NVIDIA supports across the board
Datasets are 
### Tell me about yourself
* hey as you know my name is annie 
	* born and brought up in nj in the shadow of bell labs
	* so i always grew up technical and appetite for entrepreneurship  
	* haphazard interested in biology and finance
	* what i rlly enjoyed was the messiness of data
	* brought me to cornell
	* studied data science there
	* i wanted both a technical role but also a customer centric role
	* joined microsoft a year ago 
	* there work as a tpm on supercomputing for microsoft
	* at microsoft, we're building a platform for supercomputing at scale for some of our largest customers like foundational research labs openai and microsoft ai 
	* really getting into the nitty gritty of the operational complexity of running these expensive machines for such a long time 
	* Wear a lot of hats across strategy, operations, data analysis, and customer engagement
	* i work closely with engineering team for azure batch which is a batch scheduling service for AI/ML workloads 
	* really the data guru on our team 
		* develop analytics and telemetry usage dashboards for batch 
		*  dash boards for openai 
* TPM at Microsoft Supercomputing, building out the products and frameworks for supercomputing at scale 
* Wear a lot of hats across strategy, operations, data analysis, and customer engagement 
* Big operational headace i organize is the task of keeping the GPUs that run these large training workloads uptodate
	* how do we find the right time to roll out updates when technicallly any second lost is thousands of lost $
* another facet of my job is tracking the telemetry and usage for azure batch, which is a batch scheduler on the cloud servicing large AI/ML workloads 

scheduling a 45 min interview w SPL team
- SQL Assessment 
	- Problem Solving 
	- Solving for Basic Level
	- Drawing, Grouping, Filtering
	- How you go thru a Dataset, Digest it, what do you come up with thats happening, what action we should take on that 
	- Brush up on SQL
	- HackerRank
- Next Step is a Case Study 
	- Creating a dataet that we would send to a client
- Final interviews - 3 hours 
	- Hiing Manager Interview
	- Problem Solving
	- Credo Interview
	- 
### Why Scale? 
choosing my next company depends on where i see the most potential for impact 
relies on three things - right industry, right scope, right team
right industry 
over my time both in college and past year workign closely with research labs i developed a ton of conviction that a) the biggest bottleneck to agi and its future and the quality of data and amount being produce
b) theres a ton of variability in places on the tech stack that i could owrk at if i want to work in ai 
but for me i want to work on the messiest and most foudnational layer that is the prereq for everything
whether its the protocol layer or application layer 
- I am deeply convinced in thorough data collection and processing being the great unlock for everything that's been happening with GenAi
- we're hitting asymptotes with compute
right scope
- Appetite to grow really quickly and take ownership since day 1
- Problem-solving skills and the ability to own a business outcome. And there's not one specific skill that's necessary for that, but I think gaining confidence in my ability to do that, and gaining experience in doing that has been very valuable.
- scale ai stands out , strategics project lead as an end to end 
- 
right people
* looked up to alexander wangs story of realizing data was a bottleneck for ai performance early on and having the conviction to drop out 
### Tell me about a time you used data to make a decision 
At Microsoft Azure's AI Supercomputing division, I faced a critical decision about how to allocate our limited GPU resources across different customer segments. This was particularly challenging because we had competing demands from established enterprise customers, high-growth AI startups, and internal Microsoft research teams.

To make this decision objectively, I built a comprehensive data analytics framework using SQL dashboards that tracked several key metrics: utilization patterns, revenue per compute hour, growth trajectories, and strategic alignment scores for each customer segment.

The data revealed several unexpected insights. While enterprise customers generated higher immediate revenue, the usage data showed that AI startups were growing their compute needs at 3x the rate and were much more efficient with their resource utilization—running jobs at 85% efficiency compared to 60% for enterprise customers. The data also highlighted that certain research workloads, while not immediately revenue-generating, were enabling capabilities that our commercial customers would need within 6-12 months.

Based on this analysis, I made the decision to implement a dynamic allocation model that reserved 50% of capacity for high-efficiency growth customers, 30% for enterprise accounts, and 20% for strategic research initiatives. This was a significant shift from our previous static allocation model.

I presented this data-backed recommendation to our executive team with clear visualizations showing the projected 18-month impact. The decision was approved, and within two quarters, we saw a 22% increase in overall revenue and a 15% improvement in infrastructure utilization. Most importantly, this data-driven approach allowed us to make what could have been a contentious decision in a way that all stakeholders could understand and support, even if their immediate allocation was reduced.

This experience reinforced my belief that when facing complex decisions with competing priorities, collecting the right data and analyzing it systematically can reveal solutions that might not be obvious through intuition alone.

### "Tell me about a time you had to scale a team or process quickly. What challenges did you face and how did you overcome them?"

, you will build innovative processes that turn human knowledge into frontier data that expands the limits of the world’s top LLMs.  

### "Tell us about a complex operational problem you solved. What was your approach?"
A complex operational problem I've solved is operational excellence for GPUs. Specifically, managing the process of testing important updates before they get to 

### Tell us about a time u used SQL.
"I've used both SQL and Python extensively for data analysis at Microsoft Azure's AI Supercomputing division, specifically for optimizing our infrastructure and detecting anomalous usage patterns.

A key example was the telemetry analysis system I built for Azure Batch, our workflow scheduler for AI workloads. The challenge was understanding resource utilization across thousands of VMs while identifying potentially fraudulent usage that affected legitimate AI customers.

For the SQL component, I designed a data pipeline that aggregated telemetry from multiple sources - VM metrics, scheduler logs, and customer data. The technical approach involved:

1. Collecting raw telemetry across a rolling window and joining it with VM and customer metadata
2. Aggregating by customer, region, and VM size to establish usage patterns
3. Applying anomaly detection rules to identify suspicious patterns, such as high GPU with minimal CPU usage

The SQL work required handling time-series data at scale, optimizing joins across distributed sources, and creating materialized views that supported real-time dashboards while processing terabytes of telemetry.

For the Python portion, I used pandas for data transformation and applied time-series analysis and clustering algorithms to identify usage patterns and outliers.

This analysis revealed that 8% of our GPU-enabled VMs showed signs of non-AI workloads, and we identified optimization opportunities that improved infrastructure utilization by 15%.

The business impact was significant: we implemented automated fraud detection that saved approximately $2M annually, and our capacity optimization insights directly improved service for high-value customers like OpenAI.


### ## "How do you identify and capitalize on growth opportunities?"
Sitch: Opportunity came from our genomics research team, who had trouble using Batch given they came from a research background. Our hypothesis was that if our internal research team was having trouble, others would as well.
We started on a very scrappy process of prototyping a copilot to help researchers easily use our infra tools and presenting them to our contacts. As the PM I worked w two other members and drove research surveys in our internal global black belt network, went to local conferences like Supercomputing to speak, and built out a multi-agent copilot to demonstrate.
There was clear appetite to build out a platform.

### "Describe a time when you had to make difficult trade-offs to meet deadlines or quality standards."
* Sitch: We need to carefully roll out updates to customers like OpenAI. There was a regression in an update and we had to choose to either try nad fix it or roll the update back.
* The developers were confused and wanted to keep hacking at the problem. But with the most familiarity of hte customers needs, which was the minmize the time window, I opted to sacrifice the quality of the update and roll it back, so we could return the customers machines on time.

In this role, you will solve problems that are ambiguous in nature, technically and operationally complex, and extraordinarily cross functional. The ideal candidate exhibits grit, ambition, empathy, an entrepreneurial spirit, operational rigor, and top-notch communication skills.  
  
We’re hiring in San Francisco and New York City. If you fit the profile and want to meaningfully contribute to the advancement of Generative AI, please use the link below to apply now!