---
title: "2025-12-11"
---

### HPE 
- didnt see new tickets
- XRD erorrs
- automation for the crawler for manual logs 
- manual is next few days
- automation by end of year 

coreweave is will 

### GCP 
20 VMs werent booting earlier this week - we dont want us to rely on us to catch 
do we hve any monitoring for unavailable nodes 
or node 
something 

[https://gcp-ext.slack.com/archives/C08KWQSTY6B/p1765218030113239](https://gcp-ext.slack.com/archives/C08KWQSTY6B/p1765218030113239)

some of our reservation in us 
leaving 14 VMs off the table


https://console.cloud.google.com/compute/reservations/detail/europe-west4-b/nvidia-b200-eeckqsgkvpx41?inv=1&invt=Ab37_Q&project=scaling-459317
is it the target side of the full reservation

nvidia-b200-eeckqsgkvpx41

### GCP-CW 
- new hardware in the issues 
- ordered new top of boxes 
	- small bit of metal is slightly sharper 
	- if you keep pulling the cables 
	- causes a health and safety
- GB200 
	- CDU issues
	- when CDU becomes unavailable - the whole rack is unavailable

1) - top of box wont cause customer downtime 
	1) reduced downtime for 32AMP

67 AMP TOB 
- 62 to do afterwards
- list of people 

HPC Net - risk that something happens that we dont expect

for the CDU issue - part is going to be replaced during 
and a new cable that needs to be installed 
work in 2 pods in 4 
electricians will do power work - elevated 
all low level work dct 
recognize 
we get the racks back soon
start monitoring back sooner
electricians to finish their activities

very sequenced 

why didnt cdu have a redundancy before - 
overall in norway - we're having a level of dc level power issues - went w a diff desing that had excellent redundancy 
- after further investigation 
norway - we still have challenges in delivering the third phase 
maintenance on the first two phases
the third phase was scheduled for january 

suspect we're going to be delayed on phase 3 of january - some challenges outside and in the shell

by the time we install phase 3 
need to go thru the exercise after this maintenance and revising the delivery date and slipping for phase 3

every time you power down/power up rack
onsite time - making sure we have vendors aligned for this 

if anything goes wrong 
make sure the work that the work required 
make sure there isnt anything started
theres a rack down at a rack level

if it ships today - first day it could start next wed
start of January 

at any opint you're going to do 4 racks at a time 

144 nodes 
= 8 racks
2 peripheral rack - IB rack 

cant do smaller 
have to do it as a row level 

have every single node and the nodes we're looking on 
would like to get a standard message
you understand waht the bot message is 
have a validation with our trial 

CDU maintenance 
instead of monitoring for 8 racks do 1 rack at a time

ASAP - before the end of January 
the sooner we get this done 

1) racks are across multiple clusters we have 

do 1 or 2 next week before christmas

agnostic order
row 9 
can do row 
top of boxes 
neeed to do sets of rows 


if we do 2 rows a day 
either do one or 

weekday work 

**there's a cable that needs to be plugged into the cdu** 
**so cdu is tied to top of box**
**otherwise we'd do cdu rack by rack** 

two rows a day 

why can't we have more people working on this ? 
this was the right crew that would have the most efficiency 
if there is a strong push to send the army
within the scope 
if we did decide to bring down for capacity 


we werent able to do the support weekly call 


### AWS
unique serial code 
if we switch out gpu board - will see same serial number, diff gpuuid if u switch 
we dont need terminate instances when host goes down 

aws tenets 
frequency of impairment speed - dont share that data 
#2 
consider that data sensitive

communicating to us if thre is an upticks

if its an nv switch - we are not able to fix 
- switch repairs 
a case where each nv swithc is conneced to each gpu 

fix an individual switch the gpus 

every gpu is every is connected to nv switch within a rack

if a switch goes down, instead of taking the rack down 
interconnect status will go down to 
NVL-72 
network fabric - across network fabric 
rack-level 
if theres an issue w the networking fabric 
we can address those isseus 
without

Stable ID 
1. Reducing time of support
2. Ultraserver 
3. 

Stable HW - early Q1 
