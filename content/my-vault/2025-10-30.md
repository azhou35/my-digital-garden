---
title: "2025-10-30"
---

![[Pasted image 20251030122906.png]]
Coreweave Reno [Reno-H100] **(Research cluster)**  
fecc0bcd-91ed-4382-b336-c50ea37eb5fa

Second one is the subscription by Avi GuptaAvi Gupta8:57 AMSecond one is the subscription CoreWeave Portland [PDX2] fecc0bcd-91ed-4... by Avi GuptaAvi Gupta8:57 AM

CoreWeave Portland [PDX2]  
fecc0bcd-91ed-4382-b336-c50ea37eb5fa

aluminum-a is 95% healthy, 102% allocated (lol)  
aluminum-b is 87% healthy. lost some nodes due to site outage over the weekend. 93% allocated

![Screenshot 2025-10-28 at 3.50.40 PM.png](https://files.slack.com/files-pri/T03025Z7DT4-F09Q4B4MZ88/screenshot_2025-10-28_at_3.50.40___pm.png)


Does quota = number of nodes or gpus ![Screenshot 2025-10-28 at 3.58.20 PM.png](https://files.slack.com/files-pri/T03025Z7DT4-F09PDKHSYNQ/screenshot_2025-10-28_at_3.58.20___pm.png)

693 healthy nodes 

I think the broader "right quota target" question is still great, but in practice over the last week I've seen 3-4 instances of a single tenant in a cluster getting prioritized out due to being at lower quota priority than others in the cluster

users should know when they're overallocated


uphold 100% uptime based on a cluster-level 85% SLA but I am curious what you as a user would prioritize?
Given the a request for the same GPU hours (less for longer, more for shorter)  

- more GPUs but lower chance of all of it staying healthy over time and nodes consistently fall off the bus, for a shorter period of time
- less GPUs but stable healthy footprint for a longer period of time

what does low priority quota mean here()