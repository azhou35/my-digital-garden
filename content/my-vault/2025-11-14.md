---
title: "2025-11-14"
---

I'm hesitant about shrinking parent quota of is currently live -- since all of Research conducted planning with a set of GPU expectations.  Shrinking would be chaotic;  Rather, I think you should shrink the cluster in the next cycle and we binpack with a reduced total, and explain we want to maintain a float because the reduced total is more accurate in terms of whats available, versus an inflated number that isn't always met. (edited) 

[3:09](https://oai-research-ah.slack.com/archives/C0853PE7QBV/p1762556954533539?thread_ts=1762461860.678869&cid=C0853PE7QBV)

I also think our planning would need to be augmented to be more granular, for every project component the min workable amount and flex / ideal amount, and we bin pack the min amount together, and bin pack flex amount separate on the same cluster (edited)

I sort of what to team up with [@alms](https://openai.enterprise.slack.com/team/U07SMDXGZD5) and create a form for people to fill out.  I don't think everyone had immediate reactions to share -- maybe a form would get us more considered responses (edited) 

![](https://ca.slack-edge.com/E03025Z7DT4-U09MBNFHZNC-f60184b484d9-48)

Annie Zhou  [7 minutes ago](https://oai-research-ah.slack.com/archives/C0853PE7QBV/p1763161416532859?thread_ts=1762461860.678869&cid=C0853PE7QBV)  

Makes sense, i guess it'd be less of a "which projects can fit onto flex" and moreso "which projects have specific workloads that could be pre-emptible" - that granularity may be harder to capture in the current compute planning sheet (maybe in the "min workable amount" you had suggested)  
The form would be a good forcing function - i think some understanding of "which workloads can tolerate pre-emption" and "what %" can also give us feedback on what a realistic buffer is ahead of implementing something next cycle